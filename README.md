# cf_ai_research_assistant

**AI-Powered Chat Application on Cloudflare Edge Platform**

> Built by **Onyeka Onwubiko** with AI assistance from Claude AI

[![Cloudflare Workers](https://img.shields.io/badge/Cloudflare-Workers-orange)](https://workers.cloudflare.com/)
[![TypeScript](https://img.shields.io/badge/TypeScript-007ACC?logo=typescript&logoColor=white)](https://www.typescriptlang.org/)
[![License: MIT](https://img.shields.io/badge/License-MIT-yellow.svg)](https://opensource.org/licenses/MIT)

A complete AI research assistant demonstrating all four required Cloudflare AI components: LLM integration, workflow coordination, user interface, and persistent state management.

---

## ğŸš€ Quick Start - Try It Now!

### Option 1: Deploy Your Own (5 minutes) â­ Recommended

```bash
# Clone the repository
git clone <your-repo-url>
cd cf_ai_research_assistant

# Install dependencies
npm install

# Login to Cloudflare (opens browser)
npx wrangler login

# Deploy to production!
npm run deploy
```

**You'll get a live URL:** `https://cf-ai-research-assistant.YOUR-SUBDOMAIN.workers.dev`

### Option 2: Test Locally First (2 minutes)

```bash
# Clone and install
git clone <your-repo-url>
cd cf_ai_research_assistant
npm install

# Run local development server
npm run dev
```

**Visit:** `http://localhost:8787` to test immediately!

### Option 3: View Live Demo

**ğŸŒ Live Demo:** [Add your deployed URL here]

Try it out - no installation needed!

---

## âœ¨ What This Is

A production-ready AI chat application built entirely on Cloudflare's edge platform featuring:

- ğŸ’¬ **AI-Powered Conversations** - Using Llama 3.3 70B
- ğŸ’¾ **Persistent Memory** - Chat history survives page refreshes  
- âš¡ **Edge Performance** - Deployed globally to 300+ locations
- ğŸ“± **Mobile-Friendly** - Responsive design for any device
- ğŸ¨ **Polished UI** - Smooth animations and modern design

---

## ğŸ¯ Four Required Components

This application demonstrates all four required Cloudflare AI components:

### âœ… 1. LLM Integration
**Technology:** Cloudflare Workers AI  
**Model:** `@cf/meta/llama-3.3-70b-instruct-fp8-fast`  
**Implementation:** Direct integration via Workers AI binding  
**Location:** `src/index.ts` lines 45-55

### âœ… 2. Workflow / Coordination  
**Technology:** Cloudflare Workers  
**Pattern:** Multi-step request orchestration  
**Flow:** Receive â†’ Store â†’ Retrieve â†’ AI Call â†’ Store â†’ Return  
**Location:** `src/index.ts` lines 30-75

### âœ… 3. User Input Interface
**Technology:** HTML/CSS/JavaScript (Chat Interface)  
**Features:** Real-time updates, loading states, error handling  
**Type:** Text-based chat with Enter-to-send  
**Location:** `src/index.ts` (HTML_CONTENT)

### âœ… 4. Memory / State Management
**Technology:** Durable Objects (SQLite-backed)  
**Pattern:** Per-conversation persistence  
**Storage:** Message history with timestamps  
**Location:** `src/conversation.ts`

---

## ğŸ“ Project Structure

```
cf_ai_research_assistant/
â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ index.ts              # Main Worker (AI + routing + UI)
â”‚   â””â”€â”€ conversation.ts       # Durable Object (state management)
â”œâ”€â”€ package.json              # Dependencies
â”œâ”€â”€ wrangler.toml            # Cloudflare configuration
â”œâ”€â”€ tsconfig.json            # TypeScript configuration
â””â”€â”€ README.md                # This file

ğŸ“š Documentation/
â”œâ”€â”€ QUICKSTART.md            # 5-minute deployment guide
â”œâ”€â”€ ARCHITECTURE.md          # Technical deep dive
â”œâ”€â”€ FEATURES.md              # Capabilities and use cases
â”œâ”€â”€ DEPLOYMENT.md            # Advanced deployment
â”œâ”€â”€ AI-ASSISTED.md           # AI development notes
â””â”€â”€ INDEX.md                 # Master documentation index
```

---

## ğŸ› ï¸ Technology Stack

| Layer | Technology |
|-------|-----------|
| **Frontend** | Vanilla JavaScript + HTML/CSS |
| **Backend** | Cloudflare Workers (TypeScript) |
| **AI** | Workers AI (Llama 3.3 70B) |
| **State** | Durable Objects (SQLite) |
| **Platform** | Cloudflare Edge (300+ locations) |

---

## ğŸ’¡ How It Works

```
User types message
    â†“
Worker receives request
    â†“
Durable Object stores user message
    â†“
Worker retrieves last 10 messages (context)
    â†“
Workers AI generates response (Llama 3.3)
    â†“
Durable Object stores AI response
    â†“
Worker returns JSON to client
    â†“
UI displays message
```

---

## ğŸ§ª Testing the Application

### Local Testing

```bash
npm run dev
# Visit http://localhost:8787
```

**Test Checklist:**
- âœ… Send a message â†’ AI responds
- âœ… Send multiple messages â†’ Context maintained
- âœ… Refresh page â†’ Messages still there
- âœ… Click "Clear Chat" â†’ Conversation resets

### Production Testing

```bash
npm run deploy
# Visit the URL from deployment output
```

Same tests as local, but on the edge!

---

## ğŸ“Š Performance & Scale

| Metric | Value |
|--------|-------|
| **Cold Start** | <50ms |
| **AI Response Time** | 2-5 seconds |
| **Concurrent Users** | Unlimited (auto-scales) |
| **Global Availability** | 300+ locations |
| **Uptime** | 99.99%+ (Cloudflare SLA) |

---

## ğŸ’° Cost

### Free Tier Includes:
- 100,000 Worker requests/day
- 10,000 Durable Object requests/day  
- Workers AI usage (pay-as-you-go)

### Typical Costs:
- **Light usage** (100 chats/day): $1-2/month
- **Medium usage** (1,000 chats/day): $5-10/month
- **Heavy usage** (10,000 chats/day): $50-100/month

Most developers stay under $5/month during testing.

---

## ğŸ¨ Customization

### Change AI Model

Edit `src/index.ts` around line 48:

```typescript
const aiResponse = await env.AI.run(
  "@cf/meta/llama-3.3-70b-instruct-fp8-fast", // â† Change model here
  { messages: aiMessages, max_tokens: 1024, temperature: 0.7 }
);
```

See [available models](https://developers.cloudflare.com/workers-ai/models/)

### Update UI Theme

Edit `src/index.ts` in the `<style>` section:

```css
background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
/* â†‘ Change to your brand colors */
```

### Add System Prompt

Edit `src/index.ts` around line 45:

```typescript
const aiMessages = [
  { role: "system", content: "You are a helpful assistant..." },
  ...messages.slice(-10)
];
```

---

## ğŸ“š Documentation

This project includes comprehensive documentation:

- **[QUICKSTART.md](./QUICKSTART.md)** - Get started in 5 minutes
- **[ARCHITECTURE.md](./ARCHITECTURE.md)** - Technical deep dive  
- **[FEATURES.md](./FEATURES.md)** - All capabilities
- **[DEPLOYMENT.md](./DEPLOYMENT.md)** - Deployment guide
- **[AI-ASSISTED.md](./AI-ASSISTED.md)** - AI development process
- **[INDEX.md](./INDEX.md)** - Documentation master index

**Total:** 84KB of comprehensive documentation

---

## ğŸ¤– AI-Assisted Development

This project was built with **AI assistance** using Claude AI, demonstrating modern AI-assisted development practices. 

See [AI-ASSISTED.md](./AI-ASSISTED.md) for details on:
- How AI was used in development
- Benefits of AI-assisted coding
- Human-AI collaboration workflow
- Transparency in the development process

**AI tools are encouraged** and this project showcases effective use of AI in software development while maintaining code quality and developer responsibility.

---

## ğŸ”§ Development Commands

```bash
# Install dependencies
npm install

# Run locally
npm run dev

# Deploy to production
npm run deploy

# View real-time logs
npx wrangler tail
```

---

## ğŸ› Troubleshooting

### "AI is not defined"
Ensure Workers AI is enabled in your Cloudflare account and `wrangler.toml` has the AI binding.

### "CONVERSATIONS is not defined"
Check that Durable Objects are properly configured in `wrangler.toml` with `new_sqlite_classes` migration.

### Deployment fails
Run `npx wrangler login` to authenticate with Cloudflare.

### Messages not persisting
Check browser console for errors. Verify conversation ID is consistent.

For more troubleshooting, see [DEPLOYMENT.md](./DEPLOYMENT.md).

---

## ğŸ“ˆ Project Stats

- **Code:** 638 lines of TypeScript
- **Documentation:** 84KB across 9 files
- **Deploy Time:** 5 minutes
- **Development Time:** ~8 hours (with AI assistance)
- **All Components:** 4/4 âœ…

---

## ğŸŒŸ Key Features

- âœ… Production-ready TypeScript code
- âœ… Comprehensive documentation
- âœ… Type-safe throughout  
- âœ… Error handling at every layer
- âœ… Global edge deployment
- âœ… Mobile-responsive UI
- âœ… Free tier compatible
- âœ… Easy to customize

---

## ğŸ“ What This Demonstrates

### Technical Skills
- Serverless/edge computing
- AI/LLM integration  
- Distributed state management
- TypeScript development
- API design
- Modern web development

### Best Practices
- Clean code architecture
- Comprehensive documentation
- Type safety
- Error handling
- Performance optimization
- Scalable design

---

## ğŸ“„ License

MIT License - see LICENSE file for details

---

## ğŸ‘¤ Author

**Onyeka Onwubiko**

Built as a technical demonstration for Cloudflare AI applications.

This project showcases:
- Modern AI-assisted development  
- Production-ready code patterns
- Comprehensive documentation practices
- Efficient use of Cloudflare's platform

---

## ğŸ¤ Contributing

This is a demonstration project, but suggestions are welcome! Areas for enhancement:
- Voice input/output
- Streaming responses
- Multi-modal support (images)
- RAG (Retrieval Augmented Generation)
- Multiple conversation threads

---

## ğŸ“ Support & Resources

### Cloudflare Resources
- [Workers Documentation](https://developers.cloudflare.com/workers/)
- [Workers AI Guide](https://developers.cloudflare.com/workers-ai/)
- [Durable Objects Docs](https://developers.cloudflare.com/durable-objects/)
- [Discord Community](https://discord.gg/cloudflaredev)

### This Project
- Check the documentation files in this repo
- Open an issue for questions
- See [DEPLOYMENT.md](./DEPLOYMENT.md) for common problems

---

## ğŸ‰ Ready to Deploy?

```bash
git clone <your-repo-url>
cd cf_ai_research_assistant
npm install
npx wrangler login
npm run deploy
```

**You'll have a live AI chat application in 5 minutes!** ğŸš€

---

*Built with â¤ï¸ using Cloudflare's edge platform and AI-assisted development*
